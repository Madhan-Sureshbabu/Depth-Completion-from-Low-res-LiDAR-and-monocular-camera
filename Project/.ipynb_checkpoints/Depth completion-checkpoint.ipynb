{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_read_depthCompletion import *\n",
    "from helper_depthCompletion import *\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import torch\n",
    "from scipy.optimize import least_squares\n",
    "import os\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_params = dict( maxCorners = 100,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7,\n",
    "                       useHarrisDetector=False)\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 6,\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "num_frames = 5\n",
    "n_features = 30\n",
    "data_loader=Data_load(input_line=16, frames=num_frames)\n",
    "lidar_frames,gt_frames,img_frames,index_list=data_loader.read_frames(batch_size=1, if_removal=False, index = 77015 )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perspective-n-Point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './depth_selection/KITTI/calib/2011_10_03/calib_cam_to_cam.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c19110f1d11b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mframe_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mK\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_loader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_camera_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mnc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnpCloud\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlidar_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlidar_frames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mframe_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mT_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/host/Project/data_read_depthCompletion.py\u001b[0m in \u001b[0;36mget_camera_matrix\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    178\u001b[0m         \u001b[0mfile_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./depth_selection/KITTI/calib/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mscene_date\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/calib_cam_to_cam.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m         \u001b[0mf_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcamera_id\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'image_02'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './depth_selection/KITTI/calib/2011_10_03/calib_cam_to_cam.txt'"
     ]
    }
   ],
   "source": [
    "frame_id = 0\n",
    "\n",
    "K = data_loader.get_camera_matrix()\n",
    "nc = npCloud(K,lidar_frames[frame_id,:,:,0].shape[0],lidar_frames[frame_id,:,:,0].shape[1])\n",
    "T_list = []\n",
    "\n",
    "while (frame_id < num_frames-1):\n",
    "    features = find_keypoints(img_frames[frame_id,:,:,:],lidar_frames[frame_id,:,:,0],feature_params,n_features)\n",
    "    next_features, status, error = track_features(img_frames[frame_id,:,:,:],features,img_frames[frame_id+1,:,:,:],lk_params)\n",
    "    features = features[status==1]\n",
    "    next_features = next_features[status==1]\n",
    "\n",
    "    image = np.copy(img_frames[frame_id,:,:,:])\n",
    "    next_image = np.copy(img_frames[frame_id+1,:,:,:])\n",
    "    for i in range(len(features)):\n",
    "        cv2.circle(image,(features[i][0],features[i][1]),10,(0,0,255),-1)\n",
    "        cv2.circle(next_image,(next_features[i][0],next_features[i][1]),10,(0,0,255),-1)\n",
    "\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "\n",
    "    plt.imshow(next_image)\n",
    "    plt.show()\n",
    "\n",
    "    pts_3d_1 = nc.calc3DPoints(lidar_frames[frame_id,:,:,:],features)\n",
    "    pts_2d_2 = []\n",
    "    for i in range(len(features)):\n",
    "        x = int(next_features[i,0])\n",
    "        y = int(next_features[i,1])\n",
    "        pts_2d_2.append([x,y])\n",
    "    pts_2d_2 = np.asarray(pts_2d_2)\n",
    "    print(\"Total points : \",len(pts_2d_2))\n",
    "    P = np.hstack((K,np.zeros((3,1))))\n",
    "    pts_3d_1 = np.expand_dims(pts_3d_1.astype(np.float32),axis=1)\n",
    "    pts_2d_2 = np.expand_dims(pts_2d_2.astype(np.float32),axis=1)\n",
    "    \n",
    "    ret = cv2.solvePnPRansac(pts_3d_1,pts_2d_2,P[:3,:3],distCoeffs=None)\n",
    "    print(\"Solution found : \",ret[0])\n",
    "\n",
    "    r, _ = cv2.Rodrigues(ret[1])\n",
    "    transf_matrix = np.hstack((r,ret[2]))\n",
    "    transf_matrix = np.vstack((transf_matrix,np.array([0,0,0,1])))\n",
    "    print(\"T (from solvePnPRansac) : \")\n",
    "    print(transf_matrix)\n",
    "    T_list.append(transf_matrix)\n",
    "    \n",
    "##    scipy least squares optimization of reprojection error\n",
    "#     pts_3d_1 = np.hstack( (np.squeeze(pts_3d_1), np.ones(( len(pts_3d_1),1) )))\n",
    "#     pts_2d_2 = np.hstack( (np.squeeze(pts_2d_2), np.ones(( len(pts_2d_2),1) )))\n",
    "\n",
    "#     dSeed = np.zeros(len(pts_3d_1))\n",
    "#     opt = least_squares(func,dSeed,method='lm',verbose=0,args=(pts_3d_1,pts_2d_2,P))\n",
    "#     R = genEulerZXZMatrix(opt.x[0],opt.x[1],opt.x[2])\n",
    "#     t = np.asarray([[opt.x[3]],[opt.x[4]],[opt.x[5]]])\n",
    "#     T = np.hstack((R,t))\n",
    "#     T = np.vstack((T,np.asarray([[0,0,0,1]])))\n",
    "#     print(\"T (from scipy least_squares) : \")\n",
    "#     print(T)\n",
    "    frame_id += 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data_loader.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depth concatenation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_id = 0\n",
    "pts3_tempList = []\n",
    "# finding 3D points for all valid pixels in depth image\n",
    "while (frame_id < num_frames) :\n",
    "    depth = lidar_frames[frame_id,:,:,0]\n",
    "    pts3 = nc.calc3DPoints(depth)\n",
    "    pts3_tempList.append(pts3)\n",
    "    frame_id += 1\n",
    "    \n",
    "# finding transformation from ith frame to the last frame\n",
    "i = len(T_list)-1\n",
    "T_intermToLast = [T_list[i]]\n",
    "while (i>0) :\n",
    "    T_temp = np.matmul(T_intermToLast[0],T_list[i-1])\n",
    "    T_intermToLast.insert(0,T_temp)\n",
    "    i -= 1\n",
    "\n",
    "# representing all 3D points wrt the last frame\n",
    "frame_id = 0\n",
    "pts3_concatenated = np.asarray([]).reshape(0,3)\n",
    "while (frame_id < num_frames-1): \n",
    "    pts3 = pts3_tempList[frame_id]\n",
    "    T = T_intermToLast[frame_id]\n",
    "    pts3 = nc.transform_points(pts3,T)\n",
    "    pts3_concatenated = np.vstack((pts3_concatenated,pts3[:,:3]))\n",
    "    frame_id += 1\n",
    "\n",
    "pts3_concatenated = np.vstack((pts3_concatenated,pts3_tempList[num_frames-1][:,:3]))\n",
    "depth_concatenated = np.zeros(lidar_frames[0,:,:,0].shape)\n",
    "\n",
    "# finding 2D projections of all 3D points in the last frame\n",
    "u,v,z = nc.calc2DPoints(pts3_concatenated)\n",
    "\n",
    "print(num_frames,\" sparse lidar frames \")\n",
    "for i in range(num_frames):\n",
    "    print(\"Id : \",i)\n",
    "    plt.imshow(lidar_frames[i,:,:,0])\n",
    "    plt.show()\n",
    "\n",
    "depth_concatenated[v,u] = z\n",
    "\n",
    "gt_img = gt_frames[num_frames-1,:,:,0]\n",
    "sparse_depth_img = lidar_frames[num_frames-1,:,:,0]\n",
    "\n",
    "print(\"Ground truth depth image : \")\n",
    "plt.imshow(gt_img)\n",
    "plt.show()\n",
    "\n",
    "rmse = nc.calcRMSE(gt_img,sparse_depth_img)\n",
    "print(\"number of points in sparse depth image \",np.where(sparse_depth_img!=0)[0].shape[0])\n",
    "print(\"RMSE between GT & sparse depth image : \",rmse)\n",
    "print(\"--------\")\n",
    "\n",
    "print(\"Concatenated depth image : \")\n",
    "plt.imshow(depth_concatenated)\n",
    "plt.show()\n",
    "rmse = nc.calcRMSE(gt_img,depth_concatenated)\n",
    "print(\"number of points in concatenated depth image : \",np.where(depth_concatenated!=0)[0].shape[0])\n",
    "print(\"RMSE between GT & Concatenated depth image : \",rmse)\n",
    "\n",
    "# depth_concatenated = np.where(depth_concatenated>0,100-depth_concatenated,0)\n",
    "# depth_concatenated_dilated = cv2.dilate(depth_concatenated,np.ones((5,5),np.uint8))\n",
    "# depth_concatenated_dilated = np.where(depth_concatenated_dilated>0,100-depth_concatenated_dilated,0)\n",
    "# print(\"Dilated depth concatenated image : \")\n",
    "# plt.imshow(depth_concatenated_dilated)\n",
    "# plt.show()\n",
    "\n",
    "# rmse = nc.calcRMSE(gt_img,depth_concatenated_dilated)\n",
    "# print(\"RMSE between GT & Dilated Depth concatenated image : \",rmse)\n",
    "# print(\"number of points in concatenated & dilated depth image : \",np.where(depth_concatenated_dilated!=0)[0].shape[0])\n",
    "# print(\"--------\")\n",
    "\n",
    "# depth_dilated = np.where(lidar_frames[num_frames-1,:,:,0]>0,100-lidar_frames[num_frames-1,:,:,0],0)\n",
    "# depth_dilated = cv2.dilate(depth_dilated,np.ones((5,5),np.uint8))\n",
    "# depth_dilated = np.where(depth_dilated>0,100-depth_dilated,0)\n",
    "\n",
    "# print(\"Dilated sparse depth image : \")\n",
    "# plt.imshow(depth_dilated)\n",
    "# plt.show()\n",
    "\n",
    "# rmse = nc.calcRMSE(gt_img,depth_dilated)\n",
    "# print(\"RMSE between GT & Dilated sparse depth image : \",rmse)\n",
    "# print(\"number of points in concatenated depth image\",np.where(depth_dilated!=0)[0].shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outlier rejection using SLIC (Simple Linear Iterative Clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slic import SuperPixels\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.util import img_as_float\n",
    "from skimage import io, color\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "min_diff = 2.0\n",
    "spx_list = []\n",
    "depth_concatenated_temp = np.zeros(lidar_frames[0,:,:,0].shape)\n",
    "outlier_indices = {}\n",
    "count_rejected_points = 0\n",
    "K = data_loader.get_camera_matrix() # eg: 2011_09_26, image_03\n",
    "nc = npCloud(K,lidar_frames[0].shape[0],lidar_frames[0].shape[1])\n",
    "start_time = time.time()\n",
    "for frame_id in range(num_frames) : \n",
    "    print(\"Initializing super pixels in img : \",frame_id)\n",
    "    img1 = img_frames[frame_id,:,:,:]\n",
    "    lidar_img1 = lidar_frames[frame_id,:,:,0]\n",
    "    numSegments = 300\n",
    "    compactness = 100.0\n",
    "    segments11 = slic(img1,n_segments = numSegments, sigma = 5, compactness=compactness, max_iter=100, convert2lab=True)\n",
    "\n",
    "    if frame_id < 2 : \n",
    "        print(\"Super pixels :\")\n",
    "        plt.imshow(mark_boundaries(img_frames[i,:,:,:],segments11))\n",
    "        plt.show()\n",
    "    \n",
    "    spx = SuperPixels(img1,lidar_img1)\n",
    "    spx.init_clusters(segments11)\n",
    "    \n",
    "    cluster_centres = []\n",
    "    for cluster_id in spx.clusters :\n",
    "        cluster_centres.append([spx.clusters[cluster_id].mean_col, spx.clusters[cluster_id].mean_row]) # (x,y)\n",
    "    cluster_centres = np.asarray(cluster_centres)\n",
    "    spx.update_KDtree(KDTree(cluster_centres,leaf_size=2))\n",
    "    spx_list.append(spx)\n",
    "\n",
    "print(\"Initialized super pixel objects \")\n",
    "flag = 0\n",
    "for frame_id in range(num_frames-1):\n",
    "    spx1 = spx_list[frame_id]\n",
    "    spx2 = spx_list[frame_id+1]\n",
    "    for candidate_index in spx2.clusters : \n",
    "        if  spx2.clusters[candidate_index].num_lidar_points!= 0 :\n",
    "            d_list = []\n",
    "\n",
    "            dist, nearest_cluster_indices = spx1.tree.query(spx2.clusters[candidate_index].get_centre_xy(),k=5)\n",
    "            for j,i in enumerate(nearest_cluster_indices[0]) :\n",
    "                d_list.append(spx2.clusters[candidate_index].get_distance(spx1.clusters[i],dist[0][j],0.9))\n",
    "\n",
    "            d_list = np.asarray(d_list)\n",
    "            cluster_match_index = nearest_cluster_indices[0][np.argmin(d_list)]\n",
    "\n",
    "            if (spx1.clusters[cluster_match_index].num_lidar_points!=0) :\n",
    "                spx1.clusters[cluster_match_index].match_index_next_img = candidate_index\n",
    "                spx2.clusters[candidate_index].match_index_prev_img = cluster_match_index\n",
    "                if flag == 0 and spx1.clusters[cluster_match_index].l>15:\n",
    "                    plt.imshow(color.lab2rgb(spx1.clusters[cluster_match_index].masked_img))\n",
    "                    plt.show()\n",
    "                    plt.imshow(color.lab2rgb(spx2.clusters[candidate_index].masked_img))\n",
    "                    plt.show()\n",
    "                    flag = 1\n",
    "\n",
    "print(\"Segment matching done  \")\n",
    "for frame_id in range(num_frames-1):\n",
    "    outlier_indices[frame_id] = []\n",
    "    spx1 = spx_list[frame_id]\n",
    "    spx2 = spx_list[frame_id+1]\n",
    "    T_consecutive = T_list[frame_id]\n",
    "    T_toLastFrame = T_intermToLast[frame_id]\n",
    "    for index1 in spx1.clusters : \n",
    "        index2 = spx1.clusters[index1].match_index_next_img\n",
    "        if index2 == -1 :\n",
    "            continue\n",
    "        pts3d = nc.calc3DPoints(spx1.clusters[index1].masked_lidar_img)\n",
    "        pts_transformed = nc.transform_points(pts3d,T_consecutive)\n",
    "        d1 = spx1.clusters[index1].mean_depth\n",
    "        if index2 not in spx2.clusters :\n",
    "            print(index2)\n",
    "            print(spx2.clusters.keys())\n",
    "        else : \n",
    "            d2 = spx2.clusters[index2].mean_depth\n",
    "            if (abs(d1-d2) > min_diff) : \n",
    "                outlier_indices[frame_id].append(index1)  \n",
    "                count_rejected_points += spx1.clusters[index1].num_lidar_points\n",
    "        \n",
    "            else : \n",
    "                pts3d_transformed = nc.transform_points(pts3d,T_toLastFrame) # homogeneous coordinates\n",
    "                u,v,z = nc.calc2DPoints(pts3d_transformed[:,:3]) \n",
    "                depth_concatenated_temp[v,u] = z\n",
    "\n",
    "pts3d = nc.calc3DPoints(lidar_frames[num_frames-1,:,:,0])\n",
    "u,v,z = nc.calc2DPoints(pts3d)\n",
    "depth_concatenated_temp[v,u] = z\n",
    "                \n",
    "plt.imshow(depth_concatenated_temp)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_img = gt_frames[num_frames-1,:,:,0]\n",
    "rmse = nc.calcRMSE(gt_img,depth_concatenated_temp)\n",
    "print(\"Number of points & RMSE after outlier rejection : \",np.where(depth_concatenated_temp!=0)[0].shape[0],rmse)\n",
    "\n",
    "\n",
    "sparse_depth_img = lidar_frames[num_frames-1,:,:,0]\n",
    "rmse = nc.calcRMSE(gt_img,sparse_depth_img)\n",
    "print(\"Number of points & RMSE in the sparse depth img : \",np.where(sparse_depth_img!=0)[0].shape[0],rmse)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
